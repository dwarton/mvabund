<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Fits a path of Generalised Linear Models with LASSO (or L1) penalties, and finds the best model by corss-validation. — cv.glm1path • mvabund</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Fits a path of Generalised Linear Models with LASSO (or L1) penalties, and finds the best model by corss-validation. — cv.glm1path"><meta property="og:description" content="Fits a sequence (path) of generalised linear models with LASSO penalties, using an iteratively reweighted local linearisation approach. The whole path of models is returned, as well as the one that minimises predictive log-likelihood on random test observations. Can handle negative binomial family, even with overdispersion parameter unknown, as well as other GLM families."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">
    

    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">mvabund</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">4.2.2</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../articles/mvabund.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/Offsets.html">Using offsets with count data</a>
    </li>
  </ul></li>
      </ul><ul class="nav navbar-nav navbar-right"></ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Fits a path of Generalised Linear Models with LASSO (or L1) penalties, and finds the best model by corss-validation.</h1>
    
    <div class="hidden name"><code>cv.glm1path.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Fits a sequence (path) of generalised linear models with LASSO penalties, using an iteratively reweighted local linearisation approach. The whole path of models is returned, as well as the one that minimises predictive log-likelihood on random test observations. Can handle negative binomial family, even with overdispersion parameter unknown, as well as other GLM families.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">cv.glm1path</span><span class="op">(</span><span class="va">object</span>, block <span class="op">=</span> <span class="cn">NULL</span>, best<span class="op">=</span><span class="st">"min"</span>, plot<span class="op">=</span><span class="cn">TRUE</span>, prop.test<span class="op">=</span><span class="fl">0.2</span>, n.split <span class="op">=</span> <span class="fl">10</span>,</span>
<span>    seed<span class="op">=</span><span class="cn">NULL</span>, show.progress<span class="op">=</span><span class="cn">FALSE</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>
    <dl><dt>object</dt>
<dd><p>Output from a <code><a href="glm1path.html">glm1path</a></code> fit.</p></dd>

  <dt>block</dt>
<dd><p>A factor specifying a blocking variable, where training/test splits randomly assign blocks of observations to different groups rather than breaking up observations within blocks. Default (<code>NULL</code>) will randomly split rows into test and training groups.</p></dd>

  <dt>best</dt>
<dd><p>How should the best-fitting model be determined? <code>"1se"</code> uses the one standard error rule, <code>"min"</code> (or any other value) will return the model with best predictive performance. WARNING: David needs to check se calculatios...</p></dd>

  <dt>plot</dt>
<dd><p>Logical value indicating whether to plot the predictive log-likelihood as a function of model complexity.</p></dd>

  <dt>prop.test</dt>
<dd><p>The proportion of observations (or blocks) to assign as test observations. Default value of 0.2 gives a 80:20 training:test split.</p></dd>

  <dt>n.split</dt>
<dd><p>The number of random training/test splits to use. Default is 10 but the more the merrier (and the slower).</p></dd>

  <dt>seed</dt>
<dd><p>A vector of seeds to use for the random test/training splits. This is useful if you want to be able to exactly replicate analyses, without Monte Carlo variation in the splits. Default will not used fixed seeds.</p></dd>

  <dt>show.progress</dt>
<dd><p>Logical argument, if TRUE, console will report when a run for a seed has been completed. This option has been included because this function can take yonks to run on large datasets.</p></dd>

  <dt>...</dt>
<dd><p>Further arguments passed through to <code><a href="glm1path.html">glm1path</a></code>.</p></dd>

</dl></div>
    <div id="details">
    <h2>Details</h2>
    <p>This function fits a series of LASSO-penalised generalised linear models, with different values for the LASSO penalty, as for <code><a href="glm1path.html">glm1path</a></code>. The main difference is that the best fitting model is selected by cross-validation, using <code>n.test</code> different random training/test splits to estimate predictive performance on new (test) data. Mean predictive log-likelihood (per test observation) is used as the criterion for choosing the best model, which has connections with the Kullback-Leibler distance. The <code>best</code> argument controls whether to select the model that maximises predictive log-likelihood, or the smallest model within 1se of the maximum (the '1 standard error rule').</p>
<p>All other details of this function are as for <code><a href="glm1path.html">glm1path</a></code>.</p>
    </div>
    <div id="value">
    <h2>Value</h2>
    <dl><dt>coefficients</dt>
<dd><p>Vector of model coefficients for the best-fitting model (as judged by predictive log-likelihood)</p></dd>

<dt>lambda</dt>
<dd><p>The value of the LASOS penalty parameter, lambda, for the best-fitting model (as judged by predictive log-likelihood)</p></dd>

<dt>glm1.best</dt>
<dd><p>The glm1 fit for the best-fitting model (as judged by predictive log-likelihood). For what this contains see <code><a href="glm1.html">glm1</a></code>.</p></dd>

<dt>all.coefficients</dt>
<dd><p>A matrix where each column represents the model coefficients for a fit along the path specified by <code>lambdas</code>.</p></dd>

<dt>lambdas</dt>
<dd><p>A vector specifying the path of values for the LASSO penalty, arranged from largest (strongest penalty, smallest fitted model) to smallest (giving the largest fitted model).</p></dd>

<dt>logL</dt>
<dd><p>A vector of log-likelihood values for each model along the path.</p></dd>

<dt>df</dt>
<dd><p>A vector giving the number of non-zero parameter estimates (a crude measure of degrees of freedom) for each model along the path.</p></dd>

<dt>bics</dt>
<dd><p>A vector of BIC values for each model along the path. Calculated using a penalty on model complexity as specified by input argument <code>k</code>.</p></dd>

<dt>counter</dt>
<dd><p>A vector counting how many iterations until convergence, for each model along the path.</p></dd>

<dt>check</dt>
<dd><p>A vector of logical values specifying whether or not Karush-Kuhn-Tucker conditions are satisfied at the solution.</p></dd>

<dt>phis</dt>
<dd><p>For negative binomial regression - a vector of overdispersion parameters, for each model along the path.</p></dd>

<dt>y</dt>
<dd><p>The vector of values for the response variable specified as an input argument.</p></dd>

<dt>X</dt>
<dd><p>The design matrix of p explanatory variables specified as an input argument.</p></dd>

<dt>penalty</dt>
<dd><p>The vector to be multiplied by each lambda to make the penalty for each fitted model.</p></dd>

<dt>family</dt>
<dd><p>The family argument specified as input.</p></dd>

<dt>ll.cv</dt>
<dd><p>The mean predictive log-likelihood, averaged over all observations and then over all training/test splits.</p></dd>

<dt>se</dt>
<dd><p>Estimated standard error of the mean predictive log-likelihood.</p></dd>

</dl></div>
    <div id="references">
    <h2>References</h2>
    <p>Osborne, M.R., Presnell, B. and Turlach, B.A. (2000) On the LASSO and its dual. Journal of Computational and Graphical Statistics, 9, 319-337.</p>
    </div>
    <div id="author">
    <h2>Author</h2>
    <p>David I. Warton &lt;David.Warton@unsw.edu.au&gt;</p>
    </div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p><code><a href="glm1path.html">glm1path</a></code>, \code<a href="glm1.html">glm1</a>, <code><a href="https://rdrr.io/r/stats/glm.html" class="external-link">glm</a></code>, <code><a href="https://rdrr.io/r/stats/family.html" class="external-link">family</a></code></p></div>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html" class="external-link">data</a></span><span class="op">(</span><span class="va">spider</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">Alopacce</span> <span class="op">&lt;-</span> <span class="va">spider</span><span class="op">$</span><span class="va">abund</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span></span></span>
<span class="r-in"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/model.matrix.html" class="external-link">model.matrix</a></span><span class="op">(</span><span class="op">~</span><span class="va">.</span>,data<span class="op">=</span><span class="va">spider</span><span class="op">$</span><span class="va">x</span><span class="op">)</span> <span class="co"># to get design matrix with intercept term</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># fit a LASSO-penalised negative binomial regression:</span></span></span>
<span class="r-in"><span><span class="va">ft</span> <span class="op">=</span> <span class="fu"><a href="glm1path.html">glm1path</a></span><span class="op">(</span><span class="va">Alopacce</span>,<span class="va">X</span>,lam.min<span class="op">=</span><span class="fl">0.1</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">ft</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   (Intercept)      soil.dry     bare.sand fallen.leaves          moss </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    -1.9332758    -0.6282024     0.0000000    -0.2420786     0.1581210 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    herb.layer    reflection </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>     0.6024593     0.7663732 </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># now estimate the best-fitting model by cross-validation:</span></span></span>
<span class="r-in"><span><span class="va">cvft</span> <span class="op">=</span> <span class="fu">cv.glm1path</span><span class="op">(</span><span class="va">ft</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="cv.glm1path-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">cvft</span><span class="op">)</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   (Intercept)      soil.dry     bare.sand fallen.leaves          moss </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>   -1.88479622   -0.79000588   -0.04183393   -0.26295595    0.13478827 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    herb.layer    reflection </span>
<span class="r-out co"><span class="r-pr">#&gt;</span>    0.67326991    0.81054027 </span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Yi Wang, Ulrike Naumann, Dirk Eddelbuettel, John Wilshire, David Warton.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.6.</p>
</div>

      </footer></div>

  


  

  </body></html>

